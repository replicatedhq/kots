name: build-test

on:
  pull_request_target:
    # This workflow trigger may lead to malicious PR authors being able to obtain repository write permissions or stealing repository secrets. 
    # Please read https://securitylab.github.com/research/github-actions-preventing-pwn-requests/
    types: [opened, synchronize, reopened, labeled]

concurrency:
  group: ${{ github.head_ref }}
  cancel-in-progress: true

jobs:
  can-run-ci:
    runs-on: ubuntu-20.04
    # This workflow trigger may lead to malicious PR authors being able to obtain repository write permissions or stealing repository secrets.
    # Please read https://securitylab.github.com/research/github-actions-preventing-pwn-requests/
    # only run this workflow if:
    #   not a fork or user is dependabot or PR is labeled with '@actions/safe-to-test'
    if: >
      github.event.pull_request.head.repo.full_name == github.repository ||
      github.event.pull_request.user.login == 'dependabot[bot]' ||
      contains(github.event.pull_request.labels.*.name, '@actions/safe-to-test')
    steps:
      - name: ok
        run: echo "yes"


  test-okteto-env:
    runs-on: ubuntu-latest
    needs: [can-run-ci]
    steps:
      - name: Checkout
        uses: actions/checkout@v2
      - name: Test Okteto development environment
        uses: replicatedhq/action-okteto-test@main
        with:
          token: ${{ secrets.OKTETO_TOKEN }}
          branch: ${{ github.head_ref }}


  build-web:
    runs-on: ubuntu-20.04
    needs: [can-run-ci]
    steps:
      # This workflow trigger may lead to malicious PR authors being able to obtain repository write permissions or stealing repository secrets. 
      # Please read https://securitylab.github.com/research/github-actions-preventing-pwn-requests/
      # this action checks out the remote branch and runs CI
      - name: Checkout
        uses: actions/checkout@v2
        with:
          ref: ${{github.event.pull_request.head.ref}}
          repository: ${{github.event.pull_request.head.repo.full_name}}

      - name: Get tags
        id: get_tag
        uses: ./actions/version-tag

      - name: Setup Node.js environment
        uses: actions/setup-node@v2
        with:
          node-version: '17.x'

      - name: Build web
        env:
          GIT_COMMIT: ${{ github.sha }}
          GIT_TAG: ${{ steps.get_tag.outputs.GIT_TAG }}
        run: export $(cat .image.env | sed 's/#.*//g' | xargs) && make -C web deps build-kotsadm

      - name: Upload web artifact
        uses: actions/upload-artifact@v2
        with:
          name: web
          path: ./web/dist


  build-kots:
    runs-on: ubuntu-20.04
    needs: [can-run-ci, build-web]

    steps:
      - uses: actions/setup-go@v2
        with:
          go-version: '^1.17.4'

      - name: setup env
        run: |
          echo "GOPATH=$(go env GOPATH)" >> $GITHUB_ENV
          echo "$(go env GOPATH)/bin" >> $GITHUB_PATH
        shell: bash

      - id: go-cache-paths
        run: |
          echo "::set-output name=go-build::$(go env GOCACHE)"
          echo "::set-output name=go-mod::$(go env GOMODCACHE)"

      # This workflow trigger may lead to malicious PR authors being able to obtain repository write permissions or stealing repository secrets. 
      # Please read https://securitylab.github.com/research/github-actions-preventing-pwn-requests/
      # this action checks out the remote branch and runs CI
      - uses: actions/checkout@v2
        with:
          ref: ${{github.event.pull_request.head.ref}}
          repository: ${{github.event.pull_request.head.repo.full_name}}

      - uses: actions/cache@v2
        with:
          path: ${{ steps.go-cache-paths.outputs.go-build }}
          key: ${{ runner.os }}-go-build-${{ hashFiles('**/go.sum') }}
      - uses: actions/cache@v2
        with:
          path: ${{ steps.go-cache-paths.outputs.go-mod }}
          key: ${{ runner.os }}-go-mod-${{ hashFiles('**/go.sum') }}

      - name: Download web artifact
        uses: actions/download-artifact@v2
        with:
          name: web
          path: ./web/dist
      - run: export $(cat .image.env | sed 's/#.*//g' | xargs) && make ci-test kots
      - uses: actions/upload-artifact@v2
        with:
          name: kots
          path: bin/kots


  build-kotsadm:
    runs-on: ubuntu-20.04
    needs: [can-run-ci, build-web, build-kots]
    steps:
      - uses: actions/setup-go@v2
        with:
          go-version: '^1.17.4'

      - name: setup env
        run: |
          echo "GOPATH=$(go env GOPATH)" >> $GITHUB_ENV
          echo "$(go env GOPATH)/bin" >> $GITHUB_PATH
        shell: bash

      - id: go-cache-paths
        run: |
          echo "::set-output name=go-build::$(go env GOCACHE)"
          echo "::set-output name=go-mod::$(go env GOMODCACHE)"

      # This workflow trigger may lead to malicious PR authors being able to obtain repository write permissions or stealing repository secrets. 
      # Please read https://securitylab.github.com/research/github-actions-preventing-pwn-requests/
      # this action creates a branch based on remote branch and runs the tests
      - uses: actions/checkout@v2
        with:
          ref: ${{github.event.pull_request.head.ref}}
          repository: ${{github.event.pull_request.head.repo.full_name}}
      - uses: actions/cache@v2
        with:
          path: ${{ steps.go-cache-paths.outputs.go-build }}
          key: ${{ runner.os }}-go-build-${{ hashFiles('**/go.sum') }}
      - uses: actions/cache@v2
        with:
          path: ${{ steps.go-cache-paths.outputs.go-mod }}
          key: ${{ runner.os }}-go-mod-${{ hashFiles('**/go.sum') }}

      - name: Download kots artifact
        uses: actions/download-artifact@v2
        with:
          name: kots
          path: bin/
      - run: chmod +x bin/kots

      - name: Download web artifact
        uses: actions/download-artifact@v2
        with:
          name: web
          path: ./web/dist
      - run: export $(cat .image.env | sed 's/#.*//g' | xargs) && make build
      - name: build and push kotsadm for e2e
        uses: docker/build-push-action@v2
        with:
          tags: ttl.sh/automated-${{ github.run_id }}/kotsadm:2h
          context: ./
          file: ./deploy/Dockerfile
          push: true


  build-kurl-proxy:
    runs-on: ubuntu-20.04
    needs: [can-run-ci]
    steps:
      - uses: actions/setup-go@v2
        with:
          go-version: '^1.17.4'

      - name: setup env
        run: |
          echo "GOPATH=$(go env GOPATH)" >> $GITHUB_ENV
          echo "$(go env GOPATH)/bin" >> $GITHUB_PATH
        shell: bash

      - id: go-cache-paths
        run: |
          echo "::set-output name=go-build::$(go env GOCACHE)"
          echo "::set-output name=go-mod::$(go env GOMODCACHE)"

      # This workflow trigger may lead to malicious PR authors being able to obtain repository write permissions or stealing repository secrets. 
      # Please read https://securitylab.github.com/research/github-actions-preventing-pwn-requests/
      # this action creates a branch based on remote branch and runs the tests
      - uses: actions/checkout@v2
        with:
          ref: ${{github.event.pull_request.head.ref}}
          repository: ${{github.event.pull_request.head.repo.full_name}}
      - uses: actions/cache@v2
        with:
          path: ${{ steps.go-cache-paths.outputs.go-build }}
          key: ${{ runner.os }}-go-build-${{ hashFiles('**/go.sum') }}
      - uses: actions/cache@v2
        with:
          path: ${{ steps.go-cache-paths.outputs.go-mod }}
          key: ${{ runner.os }}-go-mod-${{ hashFiles('**/go.sum') }}

      - run: export $(cat .image.env | sed 's/#.*//g' | xargs) && make -C kurl_proxy build

      - name: build and push kurl_proxy for e2e
        uses: docker/build-push-action@v2
        with:
          tags: ttl.sh/automated-${{ github.run_id }}/kurl-proxy:2h
          context: ./kurl_proxy
          file: ./kurl_proxy/deploy/Dockerfile
          push: true


  build-migrations:
    runs-on: ubuntu-20.04
    needs: [can-run-ci]
    steps:
      - uses: actions/setup-go@v2
        with:
          go-version: '^1.17.4'

      - name: setup env
        run: |
          echo "GOPATH=$(go env GOPATH)" >> $GITHUB_ENV
          echo "$(go env GOPATH)/bin" >> $GITHUB_PATH
        shell: bash

      - id: go-cache-paths
        run: |
          echo "::set-output name=go-build::$(go env GOCACHE)"
          echo "::set-output name=go-mod::$(go env GOMODCACHE)"

      # This workflow trigger may lead to malicious PR authors being able to obtain repository write permissions or stealing repository secrets. 
      # Please read https://securitylab.github.com/research/github-actions-preventing-pwn-requests/
      # this action creates a branch based on remote branch and runs the tests
      - uses: actions/checkout@v2
        with:
          ref: ${{github.event.pull_request.head.ref}}
          repository: ${{github.event.pull_request.head.repo.full_name}}
      - uses: actions/cache@v2
        with:
          path: ${{ steps.go-cache-paths.outputs.go-build }}
          key: ${{ runner.os }}-go-build-${{ hashFiles('**/go.sum') }}
      - uses: actions/cache@v2
        with:
          path: ${{ steps.go-cache-paths.outputs.go-mod }}
          key: ${{ runner.os }}-go-mod-${{ hashFiles('**/go.sum') }}

      - name: build and push migrations for e2e
        uses: docker/build-push-action@v2
        with:
          tags: ttl.sh/automated-${{ github.run_id }}/kotsadm-migrations:2h
          context: ./migrations
          file: ./migrations/deploy/Dockerfile
          push: true


  push-minio:
    runs-on: ubuntu-20.04
    needs: [can-run-ci]
    steps:
      - uses: actions/checkout@v2

      - name: load environment variables from .image.env
        uses: falti/dotenv-action@v0.2
        id: dotenv
        with:
          path: .image.env

      - name: push minio for e2e
        run: |
          docker pull minio/minio:${{ steps.dotenv.outputs.minio_tag }}
          docker tag minio/minio:${{ steps.dotenv.outputs.minio_tag }} ttl.sh/automated-${{ github.run_id }}/minio:2h
          docker push ttl.sh/automated-${{ github.run_id }}/minio:2h


  push-postgres:
    runs-on: ubuntu-20.04
    needs: [can-run-ci]
    steps:
      - uses: actions/checkout@v2

      - name: load environment variables from .image.env
        uses: falti/dotenv-action@v0.2
        id: dotenv
        with:
          path: .image.env

      - name: push postgres for CI
        run: |
          docker pull postgres:${{ steps.dotenv.outputs.postgres_alpine_tag }}
          docker tag postgres:${{ steps.dotenv.outputs.postgres_alpine_tag }} ttl.sh/automated-${{ github.run_id }}/postgres:2h
          docker push ttl.sh/automated-${{ github.run_id }}/postgres:2h


  validate-smoke-test:
    runs-on: ubuntu-20.04
    needs: [can-run-ci, build-kots, build-kotsadm, build-kurl-proxy, build-migrations, push-minio, push-postgres]
    strategy:
      fail-fast: false
      matrix:
        k8s_version: [v1.20.14-k3s2,v1.21.8-k3s2,v1.22.5-k3s2,v1.23.3-k3s1]
    steps:
      - uses: replicatedhq/action-k3s@main
        id: k3s
        with:
          version: ${{ matrix.k8s_version }}

      - name: download kots binary
        uses: actions/download-artifact@v2
        with:
          name: kots
          path: bin/

      - run: chmod +x bin/kots

      - uses: actions/setup-node@v2
        with:
          node-version: '17.x'

      - name: setup testIM
        run: npm i -g @testim/testim-cli
        shell: bash

      ## testim tests

      - name: aws credentials setup
        run: |
          cat > aws-credentials << EOL
          [default]
          aws_access_key_id=${{ secrets.TESTIM_AWS_ACCESS_KEY_ID }}
          aws_secret_access_key=${{ secrets.TESTIM_AWS_SECRET_ACCESS_KEY }}
          EOL

      - name: delete velero if exists
        run: kubectl delete ns velero --ignore-not-found

      - name: velero install
        run: |
          curl -LO https://github.com/vmware-tanzu/velero/releases/download/v1.7.1/velero-v1.7.1-linux-amd64.tar.gz && tar zxvf velero-v1.7.1-linux-amd64.tar.gz && \
          ./velero-v1.7.1-linux-amd64/velero install \
          --provider aws \
          --plugins velero/velero-plugin-for-aws:v1.3.0 \
          --bucket kots-testim-snapshots \
          --backup-location-config region=us-east-1 \
          --snapshot-location-config region=us-east-1 \
          --secret-file ./aws-credentials \
          --prefix /automated-smoke-test-${{ github.run_id }}-${{ matrix.k8s_version }}-$RANDOM \
          --use-restic

      - name: prepare smoke test
        run: |
          set +e
          ./bin/kots \
          install qakotstestim/github-actions-qa \
          --no-port-forward \
          --namespace smoke-test \
          --shared-password password \
          --kotsadm-registry ttl.sh \
          --kotsadm-namespace automated-${{ github.run_id }} \
          --kotsadm-tag 2h
          EXIT_CODE=$?
          if [ $EXIT_CODE -ne 0 ]; then
            echo "------pods:"
            kubectl -n smoke-test get pods
            echo "------kotsadm logs"
            kubectl -n smoke-test logs deployment/kotsadm
            echo "------previous kotsadm logs"
            kubectl -n smoke-test logs -p deployment/kotsadm
          fi
          exit $EXIT_CODE

      - name: get testim branch
        if: startsWith(github.ref, 'refs/heads/')
        id: get_testim_branch
        shell: bash
        run: |
          BRANCH=${GITHUB_REF/refs\/heads\//}
          if [ "$BRANCH" == "main" ]; then
            BRANCH="master"
          fi
          echo ::set-output name=TESTIM_BRANCH::${BRANCH:-master}

      - name: execute smoke test
        run: |
          set +e
          ./bin/kots admin-console -n smoke-test &
          ADMIN_CONSOLE_PID=$!
          sleep 10
          testim --token ${{ secrets.TESTIM_ACCESS_TOKEN }} --project wpYAooUimFDgQxY73r17 --grid "Testim-grid" --branch ${{ steps.get_testim_branch.outputs.TESTIM_BRANCH }} --report-file testim-report.xml --suite smoke-test --tunnel --tunnel-port 8800
          EXIT_CODE=$?
          if [ $EXIT_CODE -ne 0 ]; then
            echo "------pods:"
            kubectl -n smoke-test get pods
            echo "------kotsadm logs"
            kubectl -n smoke-test logs deployment/kotsadm
            echo "------previous kotsadm logs"
            kubectl -n smoke-test logs -p deployment/kotsadm
            echo "------velero logs"
            kubectl -n velero logs deployment/velero
          fi
          kill $ADMIN_CONSOLE_PID
          exit $EXIT_CODE

      - name: Generate support bundle on failure
        if: failure()
        env:
          # aws replicated dev account e2e-kots-support-bundle user
          AWS_ACCESS_KEY_ID: ${{ secrets.E2E_SUPPORT_BUNDLE_AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.E2E_SUPPORT_BUNDLE_AWS_SECRET_ACCESS_KEY }}
          AWS_DEFAULT_REGION: us-east-1
          KOTS_NAMESPACE: smoke-test
        run: |
          RELEASE="$(
            curl -sfL https://api.github.com/repos/replicatedhq/troubleshoot/releases/latest | \
            grep '"tag_name":' | \
            sed -E 's/.*"(v[^"]+)".*/\1/'
          )"
          curl -fsLO "https://github.com/replicatedhq/troubleshoot/releases/download/${RELEASE}/support-bundle_linux_amd64.tar.gz"
          tar xzf support-bundle_linux_amd64.tar.gz
          ./support-bundle -n "${KOTS_NAMESPACE}" https://kots.io
          BUNDLE="$(ls -1 | grep 'support-bundle-.*.tar.gz')"
          aws s3 cp "${BUNDLE}" "s3://kots-e2e-build-test-support-bundles/${BUNDLE}"
          echo "::notice ::support bundle uploaded to aws replicated-dev account s3://kots-e2e-build-test-support-bundles/${BUNDLE}"


  validate-minimal-rbac:
    runs-on: ubuntu-20.04
    needs: [can-run-ci, build-kots, build-kotsadm, build-kurl-proxy, build-migrations, push-minio, push-postgres]
    strategy:
      fail-fast: false
      matrix:
        k8s_version: [v1.20.14-k3s2,v1.21.8-k3s2,v1.22.5-k3s2,v1.23.3-k3s1]
    steps:
      - uses: replicatedhq/action-k3s@main
        id: k3s
        with:
          version: ${{ matrix.k8s_version }}

      - name: download kots binary
        uses: actions/download-artifact@v2
        with:
          name: kots
          path: bin/

      - run: chmod +x bin/kots

      - uses: actions/setup-node@v2
        with:
          node-version: '17.x'

      - name: setup testIM
        run: npm i -g @testim/testim-cli
        shell: bash

      ## testim tests

      - name: get testim branch
        if: startsWith(github.ref, 'refs/heads/')
        id: get_testim_branch
        shell: bash
        run: |
          BRANCH=${GITHUB_REF/refs\/heads\//}
          if [ "$BRANCH" == "main" ]; then
            BRANCH="master"
          fi
          echo ::set-output name=TESTIM_BRANCH::${BRANCH:-master}

      - name: prepare minimal-rbac online install
        run: |
          ./bin/kots \
          install minimal-rbac/automated \
          --no-port-forward \
          --namespace minimal-rbac \
          --shared-password password \
          --kotsadm-registry ttl.sh \
          --kotsadm-namespace automated-${{ github.run_id }} \
          --kotsadm-tag 2h

      - name: execute suite minimal-rbac
        run: |
          set +e
          ./bin/kots admin-console -n minimal-rbac &
          ADMIN_CONSOLE_PID=$!
          sleep 10
          testim --token ${{ secrets.TESTIM_ACCESS_TOKEN }} --project wpYAooUimFDgQxY73r17 --grid "Testim-grid" --branch ${{ steps.get_testim_branch.outputs.TESTIM_BRANCH }} --report-file testim-report.xml --suite minimal-rbac --tunnel --tunnel-port 8800
          EXIT_CODE=$?
          if [ $EXIT_CODE -ne 0 ]; then
            echo "------pods:"
            kubectl -n minimal-rbac get pods
            echo "------kotsadm logs"
            kubectl -n minimal-rbac logs deployment/kotsadm
            echo "------previous kotsadm logs"
            kubectl -n minimal-rbac logs -p deployment/kotsadm
          fi
          kill $ADMIN_CONSOLE_PID
          exit $EXIT_CODE

      - name: Generate support bundle on failure
        if: failure()
        env:
          # aws replicated dev account e2e-kots-support-bundle user
          AWS_ACCESS_KEY_ID: ${{ secrets.E2E_SUPPORT_BUNDLE_AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.E2E_SUPPORT_BUNDLE_AWS_SECRET_ACCESS_KEY }}
          AWS_DEFAULT_REGION: us-east-1
          KOTS_NAMESPACE: minimal-rbac
        run: |
          RELEASE="$(
            curl -sfL https://api.github.com/repos/replicatedhq/troubleshoot/releases/latest | \
            grep '"tag_name":' | \
            sed -E 's/.*"(v[^"]+)".*/\1/'
          )"
          curl -fsLO "https://github.com/replicatedhq/troubleshoot/releases/download/${RELEASE}/support-bundle_linux_amd64.tar.gz"
          tar xzf support-bundle_linux_amd64.tar.gz
          ./support-bundle -n "${KOTS_NAMESPACE}" https://kots.io
          BUNDLE="$(ls -1 | grep 'support-bundle-.*.tar.gz')"
          aws s3 cp "${BUNDLE}" "s3://kots-e2e-build-test-support-bundles/${BUNDLE}"
          echo "::notice ::support bundle uploaded to aws replicated-dev account s3://kots-e2e-build-test-support-bundles/${BUNDLE}"


  validate-minimal-rbac-override:
    runs-on: ubuntu-20.04
    needs: [can-run-ci, build-kots, build-kotsadm, build-kurl-proxy, build-migrations, push-minio, push-postgres]
    strategy:
      fail-fast: false
      matrix:
        k8s_version: [v1.20.14-k3s2,v1.21.8-k3s2,v1.22.5-k3s2,v1.23.3-k3s1]
    steps:
      - uses: replicatedhq/action-k3s@main
        id: k3s
        with:
          version: ${{ matrix.k8s_version }}

      - name: download kots binary
        uses: actions/download-artifact@v2
        with:
          name: kots
          path: bin/

      - run: chmod +x bin/kots

      - name: minimal rbac override on command line
        env:
          APP_SLUG: minimal-rbac
          APP_VERSION_LABEL: "0.0.1"
        run: |
          kubectl delete ns $APP_SLUG --ignore-not-found
          ./bin/kots \
            install $APP_SLUG/automated \
            --app-version-label $APP_VERSION_LABEL \
            --no-port-forward \
            --namespace $APP_SLUG \
            --shared-password password \
            --kotsadm-registry ttl.sh \
            --kotsadm-namespace automated-${{ github.run_id }} \
            --kotsadm-tag 2h \
            --use-minimal-rbac

          if kubectl get roles -n $APP_SLUG | grep -q kotsadm; then
            echo "Found kotsadm role in ${APP_SLUG}"
          else
            echo "No kotsadm role found in appication namespace"
            exit -1
          fi

          if kubectl get clusterroles | grep -q kotsadm; then
            echo "Found kotsadm cluster roles in minimal RBAC install"
            exit -1
          fi

      - name: no minimal rbac override on command line
        env:
          APP_SLUG: minimal-rbac
          APP_VERSION_LABEL: "0.0.1"
        run: |
          kubectl delete ns $APP_SLUG --ignore-not-found
          ./bin/kots \
            install $APP_SLUG/automated \
            --app-version-label $APP_VERSION_LABEL \
            --no-port-forward \
            --namespace $APP_SLUG \
            --shared-password password \
            --kotsadm-registry ttl.sh \
            --kotsadm-namespace automated-${{ github.run_id }} \
            --kotsadm-tag 2h

          if kubectl get roles -n $APP_SLUG | grep -q kotsadm; then
            echo "Found kotsadm role in cluster scoped install"
            exit -1
          fi

          if kubectl get clusterroles | grep -q kotsadm; then
            echo "Found kotsadm cluster role in cluster scoped install"
          else
            echo "No kotsadm cluster role in cluster scoped install"
            exit -1
          fi

      - name: Generate support bundle on failure
        if: failure()
        env:
          # aws replicated dev account e2e-kots-support-bundle user
          AWS_ACCESS_KEY_ID: ${{ secrets.E2E_SUPPORT_BUNDLE_AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.E2E_SUPPORT_BUNDLE_AWS_SECRET_ACCESS_KEY }}
          AWS_DEFAULT_REGION: us-east-1
          KOTS_NAMESPACE: minimal-rbac
        run: |
          RELEASE="$(
            curl -sfL https://api.github.com/repos/replicatedhq/troubleshoot/releases/latest | \
            grep '"tag_name":' | \
            sed -E 's/.*"(v[^"]+)".*/\1/'
          )"
          curl -fsLO "https://github.com/replicatedhq/troubleshoot/releases/download/${RELEASE}/support-bundle_linux_amd64.tar.gz"
          tar xzf support-bundle_linux_amd64.tar.gz
          ./support-bundle -n "${KOTS_NAMESPACE}" https://kots.io
          BUNDLE="$(ls -1 | grep 'support-bundle-.*.tar.gz')"
          aws s3 cp "${BUNDLE}" "s3://kots-e2e-build-test-support-bundles/${BUNDLE}"
          echo "::notice ::support bundle uploaded to aws replicated-dev account s3://kots-e2e-build-test-support-bundles/${BUNDLE}"


  validate-backup-and-restore:
    runs-on: ubuntu-20.04
    needs: [can-run-ci, build-kots, build-kotsadm, build-kurl-proxy, build-migrations, push-minio, push-postgres]
    strategy:
      fail-fast: false
      matrix:
        k8s_version: [v1.20.14-k3s2,v1.21.8-k3s2,v1.22.5-k3s2,v1.23.3-k3s1]
    steps:
      - uses: replicatedhq/action-k3s@main
        id: k3s
        with:
          version: ${{ matrix.k8s_version }}

      - name: download kots binary
        uses: actions/download-artifact@v2
        with:
          name: kots
          path: bin/

      - run: chmod +x bin/kots

      - uses: actions/setup-node@v2
        with:
          node-version: '17.x'

      - name: setup testIM
        run: npm i -g @testim/testim-cli
        shell: bash

      ## testim tests

      - name: aws credentials setup
        run: |
          cat > aws-credentials << EOL
          [default]
          aws_access_key_id=${{ secrets.TESTIM_AWS_ACCESS_KEY_ID }}
          aws_secret_access_key=${{ secrets.TESTIM_AWS_SECRET_ACCESS_KEY }}
          EOL

      - name: delete velero if exists
        run: kubectl delete ns velero --ignore-not-found

      - name: velero install
        run: |
          curl -LO https://github.com/vmware-tanzu/velero/releases/download/v1.7.1/velero-v1.7.1-linux-amd64.tar.gz && tar zxvf velero-v1.7.1-linux-amd64.tar.gz && \
          ./velero-v1.7.1-linux-amd64/velero install \
          --provider aws \
          --plugins velero/velero-plugin-for-aws:v1.3.0 \
          --bucket kots-testim-snapshots \
          --backup-location-config region=us-east-1 \
          --snapshot-location-config region=us-east-1 \
          --secret-file ./aws-credentials \
          --prefix /automated-backup-and-restore-test-${{ github.run_id }}-${{ matrix.k8s_version }}-$RANDOM \
          --use-restic

      - name: get testim branch
        if: startsWith(github.ref, 'refs/heads/')
        id: get_testim_branch
        shell: bash
        run: |
          BRANCH=${GITHUB_REF/refs\/heads\//}
          if [ "$BRANCH" == "main" ]; then
            BRANCH="master"
          fi
          echo ::set-output name=TESTIM_BRANCH::${BRANCH:-master}

      - name: prepare backup-and-restore online install
        run: |
          ./bin/kots \
          install backup-and-restore/automated \
          --no-port-forward \
          --namespace backup-and-restore \
          --shared-password password \
          --kotsadm-registry ttl.sh \
          --kotsadm-namespace automated-${{ github.run_id }} \
          --kotsadm-tag 2h

      - name: execute suite backup-and-restore
        run: |
          set +e
          ./bin/kots admin-console -n backup-and-restore &
          ADMIN_CONSOLE_PID=$!
          sleep 10
          testim --token ${{ secrets.TESTIM_ACCESS_TOKEN }} --project wpYAooUimFDgQxY73r17 --grid "Testim-grid" --branch ${{ steps.get_testim_branch.outputs.TESTIM_BRANCH }} --report-file testim-report.xml --suite backup-and-restore --tunnel --tunnel-port 8800
          EXIT_CODE=$?
          if [ $EXIT_CODE -ne 0 ]; then
            echo "------pods:"
            kubectl -n backup-and-restore get pods
            echo "------kotsadm logs"
            kubectl -n backup-and-restore logs deployment/kotsadm
            echo "------previous kotsadm logs"
            kubectl -n backup-and-restore logs -p deployment/kotsadm
          fi
          kill $ADMIN_CONSOLE_PID
          exit $EXIT_CODE

      - name: Generate support bundle on failure
        if: failure()
        env:
          # aws replicated dev account e2e-kots-support-bundle user
          AWS_ACCESS_KEY_ID: ${{ secrets.E2E_SUPPORT_BUNDLE_AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.E2E_SUPPORT_BUNDLE_AWS_SECRET_ACCESS_KEY }}
          AWS_DEFAULT_REGION: us-east-1
          KOTS_NAMESPACE: backup-and-restore
        run: |
          RELEASE="$(
            curl -sfL https://api.github.com/repos/replicatedhq/troubleshoot/releases/latest | \
            grep '"tag_name":' | \
            sed -E 's/.*"(v[^"]+)".*/\1/'
          )"
          curl -fsLO "https://github.com/replicatedhq/troubleshoot/releases/download/${RELEASE}/support-bundle_linux_amd64.tar.gz"
          tar xzf support-bundle_linux_amd64.tar.gz
          ./support-bundle -n "${KOTS_NAMESPACE}" https://kots.io
          BUNDLE="$(ls -1 | grep 'support-bundle-.*.tar.gz')"
          aws s3 cp "${BUNDLE}" "s3://kots-e2e-build-test-support-bundles/${BUNDLE}"
          echo "::notice ::support bundle uploaded to aws replicated-dev account s3://kots-e2e-build-test-support-bundles/${BUNDLE}"


  validate-no-required-config:
    runs-on: ubuntu-20.04
    needs: [can-run-ci, build-kots, build-kotsadm, build-kurl-proxy, build-migrations, push-minio, push-postgres]
    strategy:
      fail-fast: false
      matrix:
        k8s_version: [v1.23.3-k3s1] # there's no need to run this test on multiple k3s versions
    steps:
      - uses: replicatedhq/action-k3s@main
        id: k3s
        with:
          version: ${{ matrix.k8s_version }}

      - name: download kots binary
        uses: actions/download-artifact@v2
        with:
          name: kots
          path: bin/

      - run: chmod +x bin/kots

      - uses: actions/setup-node@v2
        with:
          node-version: '17.x'

      - name: setup testIM
        run: npm i -g @testim/testim-cli
        shell: bash

      ## testim tests

      - name: get testim branch
        if: startsWith(github.ref, 'refs/heads/')
        id: get_testim_branch
        shell: bash
        run: |
          BRANCH=${GITHUB_REF/refs\/heads\//}
          if [ "$BRANCH" == "main" ]; then
            BRANCH="master"
          fi
          echo ::set-output name=TESTIM_BRANCH::${BRANCH:-master}

      - name: prepare no-required-config online install
        env:
          APP_NAME: no-required-config
        run: |
          ./bin/kots \
          install $APP_NAME/automated \
          --no-port-forward \
          --namespace $APP_NAME \
          --shared-password password \
          --kotsadm-registry ttl.sh \
          --kotsadm-namespace automated-${{ github.run_id }} \
          --kotsadm-tag 2h

      - name: execute suite no-required-config
        env:
          APP_NAME: no-required-config
        run: |
          set +e
          ./bin/kots admin-console -n $APP_NAME &
          ADMIN_CONSOLE_PID=$!

          sleep 10
          echo "KOTSADM_API_TOKEN=`kubectl -n $APP_NAME get secret kotsadm-authstring -o json | jq -r '.data."kotsadm-authstring"' | base64 -d`" > .env

          testim --token ${{ secrets.TESTIM_ACCESS_TOKEN }} --project wpYAooUimFDgQxY73r17 --grid "Testim-grid" --branch ${{ steps.get_testim_branch.outputs.TESTIM_BRANCH }} --report-file testim-report.xml --suite $APP_NAME --tunnel --tunnel-port 8800
          EXIT_CODE=$?
          if [ $EXIT_CODE -ne 0 ]; then
            echo "------pods:"
            kubectl -n $APP_NAME get pods
            echo "------kotsadm logs"
            kubectl -n $APP_NAME logs deployment/kotsadm
            echo "------previous kotsadm logs"
            kubectl -n $APP_NAME logs -p deployment/kotsadm
          fi
          kill $ADMIN_CONSOLE_PID
          exit $EXIT_CODE

      - name: Generate support bundle on failure
        if: failure()
        env:
          # aws replicated dev account e2e-kots-support-bundle user
          AWS_ACCESS_KEY_ID: ${{ secrets.E2E_SUPPORT_BUNDLE_AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.E2E_SUPPORT_BUNDLE_AWS_SECRET_ACCESS_KEY }}
          AWS_DEFAULT_REGION: us-east-1
          KOTS_NAMESPACE: no-required-config
        run: |
          RELEASE="$(
            curl -sfL https://api.github.com/repos/replicatedhq/troubleshoot/releases/latest | \
            grep '"tag_name":' | \
            sed -E 's/.*"(v[^"]+)".*/\1/'
          )"
          curl -fsLO "https://github.com/replicatedhq/troubleshoot/releases/download/${RELEASE}/support-bundle_linux_amd64.tar.gz"
          tar xzf support-bundle_linux_amd64.tar.gz
          ./support-bundle -n "${KOTS_NAMESPACE}" https://kots.io
          BUNDLE="$(ls -1 | grep 'support-bundle-.*.tar.gz')"
          aws s3 cp "${BUNDLE}" "s3://kots-e2e-build-test-support-bundles/${BUNDLE}"
          echo "::notice ::support bundle uploaded to aws replicated-dev account s3://kots-e2e-build-test-support-bundles/${BUNDLE}"


  validate-multi-namespace:
    runs-on: ubuntu-20.04
    needs: [can-run-ci, build-kots, build-kotsadm, build-kurl-proxy, build-migrations, push-minio, push-postgres]
    strategy:
      fail-fast: false
      matrix:
        k8s_version: [v1.20.14-k3s2,v1.21.8-k3s2,v1.22.5-k3s2,v1.23.3-k3s1]
    steps:
      - uses: replicatedhq/action-k3s@main
        id: k3s
        with:
          version: ${{ matrix.k8s_version }}

      - name: download kots binary
        uses: actions/download-artifact@v2
        with:
          name: kots
          path: bin/

      - run: chmod +x bin/kots

      - uses: actions/setup-node@v2
        with:
          node-version: '17.x'

      - name: setup testIM
        run: npm i -g @testim/testim-cli
        shell: bash

      ## testim tests

      - name: get testim branch
        if: startsWith(github.ref, 'refs/heads/')
        id: get_testim_branch
        shell: bash
        run: |
          BRANCH=${GITHUB_REF/refs\/heads\//}
          if [ "$BRANCH" == "main" ]; then
            BRANCH="master"
          fi
          echo ::set-output name=TESTIM_BRANCH::${BRANCH:-master}

      - name: prepare multi-namespace online install
        env:
          APP_NAME: multi-namespace-yeti
        run: |
          ./bin/kots \
          install $APP_NAME/automated \
          --no-port-forward \
          --namespace $APP_NAME \
          --shared-password password \
          --kotsadm-registry ttl.sh \
          --kotsadm-namespace automated-${{ github.run_id }} \
          --kotsadm-tag 2h

      - name: execute suite multi-namespace
        env:
          APP_NAME: multi-namespace-yeti
          SUITE_NAME: multi-namespace
        run: |
          set +e
          ./bin/kots admin-console -n $APP_NAME &
          ADMIN_CONSOLE_PID=$!

          sleep 10
          echo "KOTSADM_API_TOKEN=`kubectl -n $APP_NAME get secret kotsadm-authstring -o json | jq -r '.data."kotsadm-authstring"' | base64 -d`" > .env

          # HACK: with limitted RBAC secrets are not applied by kotsadm
          echo ${{ secrets.MULTI_NAMESPACE_REGISTRY_AUTH }} | base64 -d > replicated-registry-auth.json
          kubectl -n nginx-test create secret generic multi-namespace-yeti-registry --type=kubernetes.io/dockerconfigjson --from-file=.dockerconfigjson=./replicated-registry-auth.json
          kubectl -n redis-test create secret generic multi-namespace-yeti-registry --type=kubernetes.io/dockerconfigjson --from-file=.dockerconfigjson=./replicated-registry-auth.json
          kubectl -n redis-test create secret generic multi-namespace-yeti-redis-registry --type=kubernetes.io/dockerconfigjson --from-file=.dockerconfigjson=./replicated-registry-auth.json
          kubectl -n postgres-test create secret generic multi-namespace-yeti-registry --type=kubernetes.io/dockerconfigjson --from-file=.dockerconfigjson=./replicated-registry-auth.json

          testim --token ${{ secrets.TESTIM_ACCESS_TOKEN }} --project wpYAooUimFDgQxY73r17 --grid "Testim-grid" --branch ${{ steps.get_testim_branch.outputs.TESTIM_BRANCH }} --report-file testim-report.xml --suite $SUITE_NAME --tunnel --tunnel-port 8800
          EXIT_CODE=$?
          if [ $EXIT_CODE -ne 0 ]; then
            echo "------pods:"
            kubectl get pods -A
            echo "------kotsadm logs"
            kubectl -n $APP_NAME logs deployment/kotsadm
            echo "------previous kotsadm logs"
            kubectl -n $APP_NAME logs -p deployment/kotsadm
          fi
          kill $ADMIN_CONSOLE_PID
          exit $EXIT_CODE

      - name: Generate support bundle on failure
        if: failure()
        env:
          # aws replicated dev account e2e-kots-support-bundle user
          AWS_ACCESS_KEY_ID: ${{ secrets.E2E_SUPPORT_BUNDLE_AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.E2E_SUPPORT_BUNDLE_AWS_SECRET_ACCESS_KEY }}
          AWS_DEFAULT_REGION: us-east-1
          KOTS_NAMESPACE: multi-namespace-yeti
        run: |
          RELEASE="$(
            curl -sfL https://api.github.com/repos/replicatedhq/troubleshoot/releases/latest | \
            grep '"tag_name":' | \
            sed -E 's/.*"(v[^"]+)".*/\1/'
          )"
          curl -fsLO "https://github.com/replicatedhq/troubleshoot/releases/download/${RELEASE}/support-bundle_linux_amd64.tar.gz"
          tar xzf support-bundle_linux_amd64.tar.gz
          ./support-bundle -n "${KOTS_NAMESPACE}" https://kots.io
          BUNDLE="$(ls -1 | grep 'support-bundle-.*.tar.gz')"
          aws s3 cp "${BUNDLE}" "s3://kots-e2e-build-test-support-bundles/${BUNDLE}"
          echo "::notice ::support bundle uploaded to aws replicated-dev account s3://kots-e2e-build-test-support-bundles/${BUNDLE}"


  validate-kots-pull:
    runs-on: ubuntu-20.04
    needs: [can-run-ci, build-kots, build-kotsadm, build-kurl-proxy, build-migrations, push-minio, push-postgres]
    strategy:
      fail-fast: false
      matrix:
        k8s_version: [v1.20.14-k3s2,v1.21.8-k3s2,v1.22.5-k3s2,v1.23.3-k3s1]
    steps:
      - uses: replicatedhq/action-k3s@main
        id: k3s
        with:
          version: ${{ matrix.k8s_version }}

      - name: download kots binary
        uses: actions/download-artifact@v2
        with:
          name: kots
          path: bin/

      - run: chmod +x bin/kots

      - name: run kots pull
        env:
          APP_NAME: multi-namespace-yeti
          APP_SLUG: multi-namespace
        run: |
          set +e
          echo ${{ secrets.MULTI_NAMESPACE_LICENSE }} | base64 -d > license.yaml
          ./bin/kots pull $APP_NAME/automated \
            --license-file license.yaml \
            --shared-password password \
            --namespace $APP_NAME \
            --exclude-admin-console

          kubectl create ns $APP_NAME
          kubectl create ns nginx-test
          kubectl create ns redis-test
          kubectl create ns postgres-test

          # HACK: without operator, additonal namespaces don't get image pull secrets
          echo ${{ secrets.MULTI_NAMESPACE_REGISTRY_AUTH }} | base64 -d > replicated-registry-auth.json
          kubectl -n nginx-test create secret generic multi-namespace-yeti-registry --type=kubernetes.io/dockerconfigjson --from-file=.dockerconfigjson=./replicated-registry-auth.json
          kubectl -n redis-test create secret generic multi-namespace-yeti-registry --type=kubernetes.io/dockerconfigjson --from-file=.dockerconfigjson=./replicated-registry-auth.json
          kubectl -n redis-test create secret generic multi-namespace-yeti-redis-registry --type=kubernetes.io/dockerconfigjson --from-file=.dockerconfigjson=./replicated-registry-auth.json
          kubectl -n postgres-test create secret generic multi-namespace-yeti-registry --type=kubernetes.io/dockerconfigjson --from-file=.dockerconfigjson=./replicated-registry-auth.json
          kubectl -n default create secret generic multi-namespace-yeti-registry --type=kubernetes.io/dockerconfigjson --from-file=.dockerconfigjson=./replicated-registry-auth.json

          kustomize build $PWD/$APP_SLUG/overlays/midstream | kubectl apply -f -
          kustomize build $PWD/$APP_SLUG/overlays/midstream/charts/redis | kubectl apply -f -

          EXIT_CODE=$?
          if [ $EXIT_CODE -ne 0 ]; then
            echo "Failed to apply spec"
            kubectl get pods -A
            exit $EXIT_CODE
          fi

          echo "Waiting for pods to start"

          COUNTER=1
          while [ $(kubectl get pods --no-headers | grep -v Running | grep -v Completed | wc -l) -gt 0 ]; do
            COUNTER=$[$COUNTER +1]
            if [ $COUNTER -gt 120 ]; then
              echo "Timed out waiting for pods to start"
              kubectl get pods -A
              exit -1
            fi
            sleep 1
          done

          echo "All pods started"

      - name: Generate support bundle on failure
        if: failure()
        env:
          # aws replicated dev account e2e-kots-support-bundle user
          AWS_ACCESS_KEY_ID: ${{ secrets.E2E_SUPPORT_BUNDLE_AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.E2E_SUPPORT_BUNDLE_AWS_SECRET_ACCESS_KEY }}
          AWS_DEFAULT_REGION: us-east-1
          KOTS_NAMESPACE: multi-namespace-yeti
        run: |
          RELEASE="$(
            curl -sfL https://api.github.com/repos/replicatedhq/troubleshoot/releases/latest | \
            grep '"tag_name":' | \
            sed -E 's/.*"(v[^"]+)".*/\1/'
          )"
          curl -fsLO "https://github.com/replicatedhq/troubleshoot/releases/download/${RELEASE}/support-bundle_linux_amd64.tar.gz"
          tar xzf support-bundle_linux_amd64.tar.gz
          ./support-bundle -n "${KOTS_NAMESPACE}" https://kots.io
          BUNDLE="$(ls -1 | grep 'support-bundle-.*.tar.gz')"
          aws s3 cp "${BUNDLE}" "s3://kots-e2e-build-test-support-bundles/${BUNDLE}"
          echo "::notice ::support bundle uploaded to aws replicated-dev account s3://kots-e2e-build-test-support-bundles/${BUNDLE}"


  validate-app-version-label:
    runs-on: ubuntu-20.04
    needs: [can-run-ci, build-kotsadm, build-kurl-proxy, build-migrations, push-minio, push-postgres]
    strategy:
      fail-fast: false
      matrix:
        k8s_version: [v1.23.3-k3s1] # there's no need to run this test on multiple k3s versions
    steps:
      - uses: replicatedhq/action-k3s@main
        id: k3s
        with:
          version: ${{ matrix.k8s_version }}
          ports: '30000:30000'

      - name: download kots binary
        uses: actions/download-artifact@v2
        with:
          name: kots
          path: bin/

      - run: chmod +x bin/kots

      - name: test kots install with version label
        env:
          APP_SLUG: app-version-label
          APP_VERSION_LABEL: v1.0.0
        run: |
          set +e
          echo ${{ secrets.APP_VERSION_LABEL_LICENSE }} | base64 -d > license.yaml
          ./bin/kots \
            install $APP_SLUG/automated \
            --license-file license.yaml \
            --app-version-label $APP_VERSION_LABEL \
            --no-port-forward \
            --namespace $APP_SLUG \
            --shared-password password \
            --kotsadm-registry ttl.sh \
            --kotsadm-namespace automated-${{ github.run_id }} \
            --kotsadm-tag 2h

          COUNTER=1
          while [ $(./bin/kots get apps --namespace $APP_SLUG | awk 'NR>1{print $3}') != "$APP_VERSION_LABEL" ]; do
            COUNTER=$[$COUNTER +1]
            if [ $COUNTER -gt 120 ]; then
              echo "Timed out waiting for app to be installed with correct version label: $APP_VERSION_LABEL"
              ./bin/kots get apps --namespace $APP_SLUG
              exit -1
            fi
            sleep 1
          done

          printf "App is installed successfully with the correct version label: $APP_VERSION_LABEL\n\n"
          ./bin/kots get apps --namespace $APP_SLUG

          # test setting DockerHub credentials

          set +e

          # TODO: deploy and check secrets are actually created and images are pulled
          ./bin/kots docker ensure-secret --dockerhub-username replicatedtests --dockerhub-password ${{ secrets.DOCKERHUB_RATELIMIT_PASSWORD }} -n $APP_SLUG
          ./bin/kots download -n $APP_SLUG --slug $APP_SLUG
          if grep ${APP_SLUG}-kotsadm-dockerhub -w ./${APP_SLUG}/overlays/midstream/secret.yaml; then
            echo "Found DockerHub secret in ${APP_SLUG} latest version"
          else
            echo "No DockerHub secret found in appication namespace"
            exit -1
          fi

      - name: remove the app
        env:
          APP_SLUG: app-version-label
        run: |
          set +e
          ./bin/kots remove $APP_SLUG --namespace $APP_SLUG --force

      - name: test kots install without version label
        env:
          APP_SLUG: app-version-label
          LATEST_APP_VERSION_LABEL: v1.0.1
        run: |
          set +e
          echo ${{ secrets.APP_VERSION_LABEL_LICENSE }} | base64 -d > license.yaml
          ./bin/kots \
            install $APP_SLUG/automated \
            --license-file license.yaml \
            --no-port-forward \
            --namespace $APP_SLUG \
            --shared-password password \
            --kotsadm-registry ttl.sh \
            --kotsadm-namespace automated-${{ github.run_id }} \
            --kotsadm-tag 2h

          COUNTER=1
          while [ $(./bin/kots get apps --namespace $APP_SLUG | awk 'NR>1{print $3}') != "$LATEST_APP_VERSION_LABEL" ]; do
            COUNTER=$[$COUNTER +1]
            if [ $COUNTER -gt 120 ]; then
              echo "Timed out waiting for app to be installed with latest version label: $LATEST_APP_VERSION_LABEL"
              ./bin/kots get apps --namespace $APP_SLUG
              exit -1
            fi
            sleep 1
          done

          printf "App is installed successfully with the correct version label: $LATEST_APP_VERSION_LABEL\n\n"
          ./bin/kots get apps --namespace $APP_SLUG

      - name: Generate support bundle on failure
        if: failure()
        env:
          # aws replicated dev account e2e-kots-support-bundle user
          AWS_ACCESS_KEY_ID: ${{ secrets.E2E_SUPPORT_BUNDLE_AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.E2E_SUPPORT_BUNDLE_AWS_SECRET_ACCESS_KEY }}
          AWS_DEFAULT_REGION: us-east-1
          KOTS_NAMESPACE: app-version-label
        run: |
          RELEASE="$(
            curl -sfL https://api.github.com/repos/replicatedhq/troubleshoot/releases/latest | \
            grep '"tag_name":' | \
            sed -E 's/.*"(v[^"]+)".*/\1/'
          )"
          curl -fsLO "https://github.com/replicatedhq/troubleshoot/releases/download/${RELEASE}/support-bundle_linux_amd64.tar.gz"
          tar xzf support-bundle_linux_amd64.tar.gz
          ./support-bundle -n "${KOTS_NAMESPACE}" https://kots.io
          BUNDLE="$(ls -1 | grep 'support-bundle-.*.tar.gz')"
          aws s3 cp "${BUNDLE}" "s3://kots-e2e-build-test-support-bundles/${BUNDLE}"
          echo "::notice ::support bundle uploaded to aws replicated-dev account s3://kots-e2e-build-test-support-bundles/${BUNDLE}"


  validate-strict-preflight-checks:
    runs-on: ubuntu-20.04
    needs: [can-run-ci, build-kotsadm, build-kurl-proxy, build-migrations, push-minio, push-postgres]
    strategy:
      fail-fast: false
      matrix:
        k8s_version: [v1.23.3-k3s1] # there's no need to run this test on multiple k3s versions
    steps:
      - uses: actions/checkout@v2
        with:
          ref: ${{github.event.pull_request.head.ref}}
          repository: ${{github.event.pull_request.head.repo.full_name}}

      - uses: replicatedhq/action-k3s@main
        id: k3s
        with:
          version: ${{ matrix.k8s_version }}
          ports: '30000:30000'

      - name: download kots binary
        uses: actions/download-artifact@v2
        with:
          name: kots
          path: bin/

      - run: chmod +x bin/kots

      - uses: actions/setup-node@v2
        with:
          node-version: '17.x'

      - name: setup testim
        run: npm i -g @testim/testim-cli

      ## testim tests
      - name: get testim branch
        if: startsWith(github.ref, 'refs/heads/')
        id: get_testim_branch
        run: |
          BRANCH=${GITHUB_REF/refs\/heads\//}
          if [ "$BRANCH" == "main" ]; then
            BRANCH="master"
          fi
          echo ::set-output name=TESTIM_BRANCH::${BRANCH:-master}

      - name: prepare strict-preflight-checks online install
        env:
          APP_NAME: strict-preflight-checks
        run: |
          ./bin/kots \
          install $APP_NAME/automated \
          --no-port-forward \
          --namespace $APP_NAME \
          --shared-password password \
          --kotsadm-registry ttl.sh \
          --kotsadm-namespace automated-${{ github.run_id }} \
          --kotsadm-tag 2h

      - name: execute suite strict-preflight-checks
        env:
          APP_NAME: strict-preflight-checks
        run: |
          set +e
          ./bin/kots admin-console -n $APP_NAME &
          ADMIN_CONSOLE_PID=$!
          sleep 10
          testim --token ${{ secrets.TESTIM_ACCESS_TOKEN }} --project wpYAooUimFDgQxY73r17 --grid "Testim-grid" --branch ${{ steps.get_testim_branch.outputs.TESTIM_BRANCH }} --report-file testim-report.xml --suite $APP_NAME --tunnel --tunnel-port 8800
          EXIT_CODE=$?
          if [ $EXIT_CODE -ne 0 ]; then
            echo "------pods:"
            kubectl -n $APP_NAME get pods
            echo "------kotsadm logs"
            kubectl -n $APP_NAME logs deployment/kotsadm
            echo "------previous kotsadm logs"
            kubectl -n $APP_NAME logs -p deployment/kotsadm
          fi
          kill $ADMIN_CONSOLE_PID
          exit $EXIT_CODE

      - name: Generate support bundle on failure
        if: failure()
        env:
          # aws replicated dev account e2e-kots-support-bundle user
          AWS_ACCESS_KEY_ID: ${{ secrets.E2E_SUPPORT_BUNDLE_AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.E2E_SUPPORT_BUNDLE_AWS_SECRET_ACCESS_KEY }}
          AWS_DEFAULT_REGION: us-east-1
          KOTS_NAMESPACE: strict-preflight-checks
        run: |
          RELEASE="$(
            curl -sfL https://api.github.com/repos/replicatedhq/troubleshoot/releases/latest | \
            grep '"tag_name":' | \
            sed -E 's/.*"(v[^"]+)".*/\1/'
          )"
          curl -fsLO "https://github.com/replicatedhq/troubleshoot/releases/download/${RELEASE}/support-bundle_linux_amd64.tar.gz"
          tar xzf support-bundle_linux_amd64.tar.gz
          ./support-bundle -n "${KOTS_NAMESPACE}" https://kots.io
          BUNDLE="$(ls -1 | grep 'support-bundle-.*.tar.gz')"
          aws s3 cp "${BUNDLE}" "s3://kots-e2e-build-test-support-bundles/${BUNDLE}"
          echo "::notice ::support bundle uploaded to aws replicated-dev account s3://kots-e2e-build-test-support-bundles/${BUNDLE}"


  validate-version-history-pagination:
    runs-on: ubuntu-20.04
    needs: [can-run-ci, build-kotsadm, build-kurl-proxy, build-migrations, push-minio, push-postgres]
    strategy:
      fail-fast: false
      matrix:
        k8s_version: [v1.23.3-k3s1] # there's no need to run this test on multiple k3s versions
    steps:
      - uses: actions/checkout@v2
        with:
          ref: ${{github.event.pull_request.head.ref}}
          repository: ${{github.event.pull_request.head.repo.full_name}}

      - uses: replicatedhq/action-k3s@main
        id: k3s
        with:
          version: ${{ matrix.k8s_version }}
          ports: '30000:30000'

      - name: download kots binary
        uses: actions/download-artifact@v2
        with:
          name: kots
          path: bin/

      - run: chmod +x bin/kots

      - uses: actions/setup-node@v2
        with:
          node-version: '17.x'

      - name: setup testim
        run: npm i -g @testim/testim-cli

      ## testim tests
      - name: get testim branch
        if: startsWith(github.ref, 'refs/heads/')
        id: get_testim_branch
        run: |
          BRANCH=${GITHUB_REF/refs\/heads\//}
          if [ "$BRANCH" == "main" ]; then
            BRANCH="master"
          fi
          echo ::set-output name=TESTIM_BRANCH::${BRANCH:-master}

      - name: prepare version-history-pagination online install
        env:
          APP_SLUG: version-history-pagination
        run: |
          ./bin/kots \
            install $APP_SLUG/automated \
            --no-port-forward \
            --namespace $APP_SLUG \
            --shared-password password \
            --kotsadm-registry ttl.sh \
            --kotsadm-namespace automated-${{ github.run_id }} \
            --kotsadm-tag 2h

      - name: execute suite version-history-pagination
        env:
          APP_SLUG: version-history-pagination
        run: |
          set +e
          ./bin/kots admin-console -n $APP_SLUG &
          ADMIN_CONSOLE_PID=$!
          sleep 10
          testim --token ${{ secrets.TESTIM_ACCESS_TOKEN }} --project wpYAooUimFDgQxY73r17 --grid "Testim-grid" --branch ${{ steps.get_testim_branch.outputs.TESTIM_BRANCH }} --report-file testim-report.xml --suite $APP_SLUG --tunnel --tunnel-port 8800
          EXIT_CODE=$?
          if [ $EXIT_CODE -ne 0 ]; then
            echo "------pods:"
            kubectl -n $APP_SLUG get pods
            echo "------kotsadm logs"
            kubectl -n $APP_SLUG logs deployment/kotsadm
            echo "------previous kotsadm logs"
            kubectl -n $APP_SLUG logs -p deployment/kotsadm
          fi
          kill $ADMIN_CONSOLE_PID
          exit $EXIT_CODE

      - name: Generate support bundle on failure
        if: failure()
        env:
          # aws replicated dev account e2e-kots-support-bundle user
          AWS_ACCESS_KEY_ID: ${{ secrets.E2E_SUPPORT_BUNDLE_AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.E2E_SUPPORT_BUNDLE_AWS_SECRET_ACCESS_KEY }}
          AWS_DEFAULT_REGION: us-east-1
          KOTS_NAMESPACE: version-history-pagination
        run: |
          RELEASE="$(
            curl -sfL https://api.github.com/repos/replicatedhq/troubleshoot/releases/latest | \
            grep '"tag_name":' | \
            sed -E 's/.*"(v[^"]+)".*/\1/'
          )"
          curl -fsLO "https://github.com/replicatedhq/troubleshoot/releases/download/${RELEASE}/support-bundle_linux_amd64.tar.gz"
          tar xzf support-bundle_linux_amd64.tar.gz
          ./support-bundle -n "${KOTS_NAMESPACE}" https://kots.io
          BUNDLE="$(ls -1 | grep 'support-bundle-.*.tar.gz')"
          aws s3 cp "${BUNDLE}" "s3://kots-e2e-build-test-support-bundles/${BUNDLE}"
          echo "::notice ::support bundle uploaded to aws replicated-dev account s3://kots-e2e-build-test-support-bundles/${BUNDLE}"


  # this job will validate that all validate-* jobs succeed and is used for the github branch protection rule
  validate-success:
    runs-on: ubuntu-20.04
    needs: [validate-smoke-test, validate-minimal-rbac, validate-minimal-rbac-override, validate-backup-and-restore, validate-no-required-config, validate-multi-namespace, validate-kots-pull, validate-app-version-label, validate-strict-preflight-checks]
    steps:
      - run: echo "Validate success"
